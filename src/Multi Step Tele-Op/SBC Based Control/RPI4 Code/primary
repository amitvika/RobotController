import asyncio
import json
import cv2
import websockets
import argparse
import numpy as np
import sys
import serial  # Ensure this is the pyserial module, not a local file
from aiortc import (
    RTCPeerConnection,
    RTCSessionDescription,
    VideoStreamTrack,
    RTCIceCandidate
)
from aiortc.contrib.media import MediaPlayer
from av import VideoFrame

DEBUG_LOOP = False

class DualCameraVideoTrack(VideoStreamTrack):
    """
    Video track that captures from two webcams.
    Instead of vertically concatenating the feeds, the main feed (camera 2)
    is used as the base and a reduced-resolution version of camera 1 is
    overlaid in the top right corner (like a rear view camera).
    """
    def __init__(self, frame_rate=30):
        super().__init__()
        self.frame_rate = frame_rate
        self.frame_period = 1.0 / frame_rate
        self.frame_count = 0
        self.start = asyncio.get_event_loop().time()

        # Open first webcam (device index 0) and second webcam (device index 2).
        self.cap1 = cv2.VideoCapture(0, cv2.CAP_V4L2)
        self.cap2 = cv2.VideoCapture(2, cv2.CAP_V4L2)

        # Set resolution and frame rate for both cameras.
        for cap in [self.cap1, self.cap2]:
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv2.CAP_PROP_FPS, frame_rate)
            # Optionally, adjust the internal buffer:
            # cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

        if not self.cap1.isOpened():
            print("DEBUG: Camera 1 failed to open! Check connection and device index.")
        else:
            print("DEBUG: Camera 1 opened successfully.")
        if not self.cap2.isOpened():
            print("DEBUG: Camera 2 failed to open! Check connection and device index.")
        else:
            print("DEBUG: Camera 2 opened successfully.")

    async def next_timestamp(self):
        self.frame_count += 1
        pts = int(self.frame_count * (90000 / self.frame_rate))
        now = asyncio.get_event_loop().time()
        expected_time = self.start + self.frame_count * self.frame_period
        delay = expected_time - now
        if delay > 0:
            await asyncio.sleep(delay)
        return pts, 90000

    async def recv(self):
        pts, time_base = await self.next_timestamp()

        # Flush stale frames with a single grab (adjust if necessary).
        self.cap1.grab()
        self.cap2.grab()

        ret1, frame1 = self.cap1.read()
        ret2, frame2 = self.cap2.read()

        if not ret1 or not ret2:
            raise Exception("DEBUG: Failed to read frame from one or both USB webcams")
        
        # --- Picture-in-Picture Composition ---
        # Base image: full resolution from camera 2.
        composite_frame = frame2.copy()

        # Downscale camera 1's frame to use as an inset.
        # For example, set overlay dimensions to 1/3 of the main frame's width.
        main_h, main_w = composite_frame.shape[:2]
        overlay_w = main_w // 3  # you can adjust this factor
        # Maintain aspect ratio from camera 1 (assuming 640x480 -> 4:3 ratio).
        overlay_h = int(overlay_w * 480 / 640)
        frame1_small = cv2.resize(frame1, (overlay_w, overlay_h))

        # Overlay the small frame onto the top-right corner of the main frame.
        x_offset = main_w - overlay_w
        y_offset = 0
        composite_frame[y_offset:y_offset+overlay_h, x_offset:x_offset+overlay_w] = frame1_small

        # Optionally preview the composite feed (requires a graphical environment)
        # cv2.imshow("Composite Feed", composite_frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("DEBUG: 'q' pressed, releasing cameras and exiting.")
            self.close()

        video_frame = VideoFrame.from_ndarray(composite_frame, format="bgr24")
        video_frame.pts = pts
        video_frame.time_base = time_base
        return video_frame

    def close(self):
        """Release camera resources and close any OpenCV windows."""
        if self.cap1.isOpened():
            self.cap1.release()
        if self.cap2.isOpened():
            self.cap2.release()
        cv2.destroyAllWindows()
        print("DEBUG: Cameras and windows released.")

async def debug_loop(track):
    print("DEBUG: Starting debug loop for DualCameraVideoTrack")
    while True:
        try:
            frame = await track.recv()
            print("DEBUG: Debug loop received frame with pts:", frame.pts)
            await asyncio.sleep(0.03)
        except Exception as e:
            print("DEBUG: Exception in debug loop:", e)
            break

async def send_control_messages(ws):
    loop = asyncio.get_event_loop()
    while True:
        cmd = await loop.run_in_executor(None, input, "Enter control command (up, down, left, right): ")
        cmd = cmd.strip().lower()
        if cmd in ["up", "down", "left", "right"]:
            payload = json.dumps({"type": "control", "direction": cmd})
            await ws.send(payload)
            print("DEBUG: Sent control message:", payload)
        else:
            print("DEBUG: Unknown command, please try again.")

async def run(pc, signaling_uri, frame_rate):
    # Update UART port to the Pi's hardware UART (GPIO 14 and 15 typically map to /dev/serial0).
    uart_port = '/dev/serial0'   # <-- Updated port for GPIO UART
    uart_baud = 115200           # Adjust baud rate as required
    try:
        uart = serial.Serial(uart_port, baudrate=uart_baud, timeout=1)
        print("DEBUG: UART connected on", uart_port)
    except Exception as e:
        print("DEBUG: Failed to open UART on", uart_port, ":", e)
        return

    try:
        print("DEBUG: Connecting to:", signaling_uri)
        async with websockets.connect(signaling_uri) as ws:
            print("DEBUG: Connected to signaling server")

            @pc.on("icecandidate")
            async def on_icecandidate(e):
                candidate = e.candidate
                if candidate is not None:
                    msg = json.dumps({
                        "type": "candidate",
                        "candidate": candidate.to_json()
                    })
                    await ws.send(msg)
                    print("DEBUG: Sent ICE candidate:", msg)

            # Create the dual video track with the specified frame rate.
            video_track = DualCameraVideoTrack(frame_rate=frame_rate)
            pc.addTrack(video_track)

            # For audio input, use the default device.
            try:
                audio_player = MediaPlayer("default", format="alsa")
                if audio_player.audio:
                    pc.addTrack(audio_player.audio)
                    print("DEBUG: Added audio track from MediaPlayer using device: default")
                else:
                    print("DEBUG: No audio track available from MediaPlayer with device: default")
            except Exception as e:
                print("DEBUG: Audio capture error:", e)

            if DEBUG_LOOP:
                asyncio.create_task(debug_loop(video_track))

            # Create and send an offer.
            offer = await pc.createOffer()
            await pc.setLocalDescription(offer)
            offer_msg = json.dumps({
                "type": "offer",
                "sdp": pc.localDescription.sdp
            })
            print("DEBUG: Sending offer to server")
            await ws.send(offer_msg)
            print("DEBUG: Offer sent")

            # Start background task for sending control messages.
            asyncio.create_task(send_control_messages(ws))

            # Listen for messages from the server.
            async for msg in ws:
                print("DEBUG: Received from server:", msg)
                data = json.loads(msg)
                if data["type"] == "answer":
                    answer = RTCSessionDescription(sdp=data["sdp"], type=data["type"])
                    await pc.setRemoteDescription(answer)
                    print("DEBUG: Answer received and set")
                elif data["type"] == "candidate":
                    candidate_data = data["candidate"]
                    candidate_string = candidate_data["candidate"]
                    parts = candidate_string.split()
                    if parts and parts[0].startswith("candidate:"):
                        foundation_part = parts[0].split("candidate:")[1]
                        candidate_parts = [foundation_part] + parts[1:]
                        foundation = candidate_parts[0]
                        component = candidate_parts[1]
                        protocol = candidate_parts[2]
                        priority = int(candidate_parts[3])
                        ip = candidate_parts[4]
                        port = int(candidate_parts[5])
                        candidate_type = candidate_parts[7]
                        ice_candidate = RTCIceCandidate(
                            foundation=foundation,
                            component=int(component),
                            protocol=protocol,
                            priority=priority,
                            ip=ip,
                            port=port,
                            type=candidate_type,
                            sdpMid=candidate_data["sdpMid"],
                            sdpMLineIndex=candidate_data["sdpMLineIndex"]
                        )
                        await pc.addIceCandidate(ice_candidate)
                        print("DEBUG: Added ICE candidate from remote")
                    else:
                        print("DEBUG: Unexpected candidate string format:", candidate_string)
                elif data["type"] == "control":
                    # Extract the control message from the received data.
                    if "controlString" in data:
                        control_msg = data["controlString"]
                        print("DEBUG: Received control string:", control_msg)
                    else:
                        control_msg = data.get("direction")
                        print("DEBUG: Received control message:", control_msg)
                    # Transmit the control string via UART to the ESP32.
                    if control_msg is not None:
                        uart.write((control_msg + "\n").encode('utf-8'))
                        print("DEBUG: Sent control message via UART:", control_msg)

            await asyncio.Future()  # Keep the connection open
    finally:
        uart.close()
        print("DEBUG: UART connection closed")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="WebRTC dual camera streaming with adjustable frame rate and UART control message transmission"
    )
    parser.add_argument("--framerate", type=float, default=15, help="Frame rate for capturing video")
    args = parser.parse_args()

    pc = RTCPeerConnection()
    # For local testing, you can use:
    # signaling_uri = "ws://localhost:8080"
    signaling_uri = "ws://64.225.55.176:8080"  # Adjust this if needed

    try:
        asyncio.run(run(pc, signaling_uri, args.framerate))
    except KeyboardInterrupt:
        print("\nDEBUG: Received Ctrl-C, exiting gracefully...")
        pc.close()
        cv2.destroyAllWindows()
        sys.exit(0)
